{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous and Discrete Hidden Markvov Models\n",
    "Kaela Nelson\n",
    "\n",
    "Volume 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MFCC\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import gmmhmm\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first implement and sample from a Gaussian mixture model continuous hidden markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gmmhmm(gmmhmm, n_sim):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ------\n",
    "    gmmhmm : list of parameters for gaussian mixture model\n",
    "    n_sim: number of simulations to iterate over\n",
    "    \n",
    "    Simulates sampling from a Gaussian mixture model hidden markov model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    states : ndarray of shape (n_sim,)\n",
    "        The sequence of states\n",
    "    obs : ndarray of shape (n_sim, K)\n",
    "        The generated observations (column vectors of length K)\n",
    "    \"\"\"\n",
    "    #n_sim different observations\n",
    "    pi = gmmhmm[-1]\n",
    "    A = gmmhmm[0]\n",
    "    states = []\n",
    "    obs_ls = []\n",
    "    \n",
    "    #select initial random state\n",
    "    state = np.argmax(np.random.multinomial(1, pi))\n",
    "    states.append(state)\n",
    "    \n",
    "    #n simmulations\n",
    "    for i in range(n_sim):\n",
    "        #select initial sample\n",
    "        state = states[-1]\n",
    "        sample_component = np.argmax(states)\n",
    "        # sample gmmhmm\n",
    "        obs = np.random.multivariate_normal(means[1, sample_component, :], covars[1, sample_component, :, :])\n",
    "        state = np.argmax(np.random.multinomial(1, A[state,:]))\n",
    "        #save observation\n",
    "        obs_ls.append(obs)\n",
    "        states.append(state)\n",
    "    return states, obs_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial conditions\n",
    "A = np.array([[.65, .35], [.15, .85]])\n",
    "pi = np.array([.8, .2])\n",
    "weights = np.array([[.7, .2, .1], [.1, .5, .4]])\n",
    "means1 = np.array([[0., 17., -4.], [5., -12., -8.], [-16., 22., 2.]])\n",
    "means2 = np.array([[-5., 3., 23.], [-12., -2., 14.], [15., -32., 0.]])\n",
    "means = np.array([means1, means2])\n",
    "covars1 = np.array([5*np.eye(3), 7*np.eye(3), np.eye(3)])\n",
    "covars2 = np.array([10*np.eye(3), 3*np.eye(3), 4*np.eye(3)])\n",
    "covars = np.array([covars1, covars2])\n",
    "gmmhmm = [A, weights, means, covars, pi]\n",
    "n_sim = 8\n",
    "\n",
    "#sample gmmhmm\n",
    "states, obs = sample_gmmhmm(gmmhmm, n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement our method in order to classify each school subject within our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped Statistics of length 88186\n",
      "Skipped Statistics of length 97792\n",
      "Skipped Statistics of length 85422\n"
     ]
    }
   ],
   "source": [
    "# int, np array\n",
    "mfccs = defaultdict(list)\n",
    "subjects = [\"Mathematics\", \"Psychology\", \"Statistics\", \"PoliticalScience\", \"Biology\"]\n",
    "\n",
    "for subject in subjects:\n",
    "    #get 30 samples\n",
    "    for num in range(1, 31):\n",
    "        sample = wavfile.read(f\"Samples/{subject} ({num}).wav\")\n",
    "        rate, data = sample[0],sample[1]\n",
    "        #check if correct length\n",
    "        if len(data) != 88200:\n",
    "            print(f\"Skipped {subject} of length {len(data)}\")\n",
    "        else:\n",
    "            mfccs[subject].append(MFCC.extract(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped Biology of length 619776\n",
      "Skipped Biology of length 543744\n"
     ]
    }
   ],
   "source": [
    "folders = [\"biology\", \"mathematics\", \"polysci\", \"psychology\", \"statistics\"]\n",
    "for subject, folder in zip(subjects, folders):\n",
    "    for num in range(1, 10):\n",
    "        #read in file\n",
    "        sample = wavfile.read(f\"CDHMMSoundFiles/{folder}/{folder}_0{num}.wav\")\n",
    "        rate, data = sample[0],sample[1]\n",
    "        #check if correct length\n",
    "        if len(data) != 88200:\n",
    "            print(f\"Skipped {subject} of length {len(data)}\")\n",
    "        else:\n",
    "            mfccs[subject].append(MFCC.extract(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n):\n",
    "    \"\"\"n: number of states\n",
    "    Returns: \n",
    "    start_prob: a random initial state distribution\n",
    "    transmat: a (row-stochastic) transition matrix\"\"\"\n",
    "    #initial state\n",
    "    rand_start = np.random.rand(n)\n",
    "    start_prob = rand_start/rand_start.sum()\n",
    "    \n",
    "    #transition matrix\n",
    "    matrix = np.random.rand(n,n)\n",
    "    transmat = matrix/matrix.sum(axis=1)[:,None]\n",
    "    \n",
    "    return start_prob, transmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = defaultdict(list)\n",
    "tests = defaultdict(list)\n",
    "for word in mfccs.keys():\n",
    "    #random re-starts\n",
    "    models = []\n",
    "    logs = []\n",
    "    for i in range(10):\n",
    "        #partition into train and test\n",
    "        train = mfccs[word][:20]\n",
    "        test = mfccs[word][20:30]\n",
    "\n",
    "        #randomly initialize startprob and transition matrix\n",
    "        startprob, transmat = initialize(5)\n",
    "        model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob \n",
    "            =startprob, cvtype='diag')\n",
    "        \n",
    "        # these values for covars_prior and var should work well for this problem\n",
    "        model.covars_prior = 0.01\n",
    "        model.fit(train, init_params='mc', var=0.1)\n",
    "        \n",
    "        #save log probs\n",
    "        logs.append(model.logprob)\n",
    "        models.append(model)\n",
    "    best_models[word].append([max(logs), models[np.argmax(max(logs))]])\n",
    "    tests[word] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle test data and trained models\n",
    "with open(\"best_models\", \"wb\") as pickle_file:\n",
    "    pickle.dump(best_models,pickle_file)\n",
    "with open('best_models', 'rb') as f:\n",
    "    new_models = pickle.load(f)\n",
    "    \n",
    "with open(\"tests\", \"wb\") as pickle_file:\n",
    "    pickle.dump(tests,pickle_file)\n",
    "with open('tests', 'rb') as f:\n",
    "    new_tests = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the accuracy within each model for each subject. The results are recorded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model Mathematics has an accuracy of 1.0.\n",
      "The model Psychology has an accuracy of 0.9.\n",
      "The model Statistics has an accuracy of 0.7.\n",
      "The model PoliticalScience has an accuracy of 0.9.\n",
      "The model Biology has an accuracy of 0.6.\n"
     ]
    }
   ],
   "source": [
    "accuracy = defaultdict(list)\n",
    "#10 test samples\n",
    "subjects = ['Mathematics', 'Psychology', 'Statistics', 'PoliticalScience', 'Biology']\n",
    "\n",
    "#for each sets of tests corresponding to each model\n",
    "for test in new_tests.keys():\n",
    "    scores = []\n",
    "    #for each of the 5 models\n",
    "    for model in subjects:       \n",
    "        score = [new_models[model][0][1].score(sample) for sample in tests[test]]\n",
    "        scores.append(score)\n",
    "    #find model with max log probs score\n",
    "    max_score = np.argmax(scores, axis=0)\n",
    "    classification = [subjects[i] for i in max_score]\n",
    "#     print(classification)\n",
    "    accuracy = np.mean([classif == test for classif in classification])\n",
    "    print(f\"The model {test} has an accuracy of {accuracy}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to my models, Biology is the hardest to classify, while Mathematics is the easiest to classify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
